import time
import requests
import logging
from datetime import datetime
from typing import List, Dict, Any, Optional
from config import BASE_URL, BRANCH_IDS, PAGE_LIMIT, EXPECTED_TYPE, HEADERS_DAFTRA, SUPABASE_URL, HEADERS_SUPABASE

# Ø¥Ø¹Ø¯Ø§Ø¯ Ù†Ø¸Ø§Ù… Ø§Ù„ØªØ³Ø¬ÙŠÙ„ Ø§Ù„Ù…Ø­Ø³Ù†
logging.basicConfig(
    level=logging.INFO, 
    format="%(asctime)s - %(levelname)s - %(message)s",
    handlers=[
        logging.FileHandler('daftra_sync.log', encoding='utf-8'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

class DataValidator:
    """ÙØ¦Ø© Ù„Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ØµØ­Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù‚Ø¨Ù„ Ø§Ù„Ø¥Ø±Ø³Ø§Ù„"""
    
    @staticmethod
    def validate_invoice(invoice: Dict[str, Any]) -> Dict[str, Any]:
        """Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ØµØ­Ø© Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ÙØ§ØªÙˆØ±Ø© ÙˆØªÙ†Ø¸ÙŠÙÙ‡Ø§"""
        validated = {}
        
        # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ù…Ø¹Ø±Ù Ø§Ù„ÙØ±ÙŠØ¯
        if not invoice.get('id'):
            raise ValueError("Ù…Ø¹Ø±Ù Ø§Ù„ÙØ§ØªÙˆØ±Ø© Ù…Ø·Ù„ÙˆØ¨")
        validated['id'] = str(invoice['id'])
        
        # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø±Ù‚Ù… Ø§Ù„ÙØ§ØªÙˆØ±Ø©
        validated['invoice_no'] = str(invoice.get('no', ''))
        
        # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ØªØ§Ø±ÙŠØ® Ø§Ù„ÙØ§ØªÙˆØ±Ø©
        invoice_date = invoice.get('date')
        if invoice_date:
            try:
                # ØªØ­ÙˆÙŠÙ„ Ø§Ù„ØªØ§Ø±ÙŠØ® Ø¥Ù„Ù‰ ØµÙŠØºØ© ISO Ø¥Ø°Ø§ Ù„Ù… ÙŠÙƒÙ† ÙƒØ°Ù„Ùƒ
                if isinstance(invoice_date, str) and 'T' not in invoice_date:
                    validated['invoice_date'] = f"{invoice_date}T00:00:00"
                else:
                    validated['invoice_date'] = invoice_date
            except:
                validated['invoice_date'] = None
        else:
            validated['invoice_date'] = None
        
        # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø±Ù‚Ù…ÙŠØ©
        validated['customer_id'] = invoice.get('client_id')
        validated['total'] = float(invoice.get('summary_total', 0))
        validated['branch'] = invoice.get('branch_id')
        validated['summary_paid'] = float(invoice.get('summary_paid', 0))
        validated['summary_unpaid'] = float(invoice.get('summary_unpaid', 0))
        
        # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù†ØµÙŠØ©
        validated['client_business_name'] = str(invoice.get('client_business_name', ''))[:255]
        validated['client_city'] = str(invoice.get('client_city', ''))[:100]
        
        # Ø¥Ø¶Ø§ÙØ© ØªØ§Ø±ÙŠØ® Ø§Ù„Ø¥Ù†Ø´Ø§Ø¡
        created_at = invoice.get('created')
        if created_at:
            try:
                if isinstance(created_at, str) and 'T' not in created_at:
                    validated['created_at'] = f"{created_at}T00:00:00"
                else:
                    validated['created_at'] = created_at
            except:
                validated['created_at'] = datetime.now().isoformat()
        else:
            validated['created_at'] = datetime.now().isoformat()
        
        return validated
    
    @staticmethod
    def validate_invoice_item(item: Dict[str, Any], invoice_id: str, client_name: str = '') -> Dict[str, Any]:
        """Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ØµØ­Ø© Ø¨ÙŠØ§Ù†Ø§Øª Ø¨Ù†Ø¯ Ø§Ù„ÙØ§ØªÙˆØ±Ø© ÙˆØªÙ†Ø¸ÙŠÙÙ‡Ø§"""
        validated = {}
        
        # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ù…Ø¹Ø±Ù Ø§Ù„ÙØ±ÙŠØ¯
        if not item.get('id'):
            raise ValueError("Ù…Ø¹Ø±Ù Ø§Ù„Ø¨Ù†Ø¯ Ù…Ø·Ù„ÙˆØ¨")
        validated['id'] = str(item['id'])
        
        # Ø±Ø¨Ø· Ø§Ù„Ø¨Ù†Ø¯ Ø¨Ø§Ù„ÙØ§ØªÙˆØ±Ø©
        validated['invoice_id'] = str(invoice_id)
        
        # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø±Ù‚Ù…ÙŠØ©
        validated['quantity'] = float(item.get('quantity', 0))
        validated['unit_price'] = float(item.get('unit_price', 0))
        validated['total_price'] = float(item.get('subtotal', 0))
        
        # Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ù…Ù†ØªØ¬
        validated['product_id'] = item.get('product_id')
        validated['product_code'] = str(item.get('item', ''))[:100]
        validated['client_business_name'] = str(client_name)[:255]
        
        return validated

class SupabaseClient:
    """ÙØ¦Ø© Ù…Ø­Ø³Ù†Ø© Ù„Ù„ØªØ¹Ø§Ù…Ù„ Ù…Ø¹ Supabase"""
    
    def __init__(self, base_url: str, headers: Dict[str, str]):
        self.base_url = base_url
        self.headers = headers
        self.batch_size = 100  # Ø­Ø¬Ù… Ø§Ù„Ø¯ÙØ¹Ø©
    
    def upsert_data(self, table: str, data: List[Dict[str, Any]], label: str = "") -> Dict[str, int]:
        """Ø¥Ø¯Ø±Ø§Ø¬ Ø£Ùˆ ØªØ­Ø¯ÙŠØ« Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ÙÙŠ Ø¯ÙØ¹Ø§Øª"""
        if not data:
            logger.warning(f"Ù„Ø§ ØªÙˆØ¬Ø¯ Ø¨ÙŠØ§Ù†Ø§Øª Ù„Ø¥Ø±Ø³Ø§Ù„Ù‡Ø§ Ø¥Ù„Ù‰ Ø¬Ø¯ÙˆÙ„ {table}")
            return {"success": 0, "failed": 0}
        
        success_count = 0
        failed_count = 0
        failed_records = []
        
        # ØªÙ‚Ø³ÙŠÙ… Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø¥Ù„Ù‰ Ø¯ÙØ¹Ø§Øª
        for i in range(0, len(data), self.batch_size):
            batch = data[i:i + self.batch_size]
            batch_num = (i // self.batch_size) + 1
            total_batches = (len(data) + self.batch_size - 1) // self.batch_size
            
            logger.info(f"ğŸ”„ {label} - Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø¯ÙØ¹Ø© {batch_num}/{total_batches} ({len(batch)} Ø³Ø¬Ù„)")
            
            try:
                # Ø§Ø³ØªØ®Ø¯Ø§Ù… upsert Ù…Ø¹ ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ù…ÙØªØ§Ø­ Ø§Ù„Ø£Ø³Ø§Ø³ÙŠ
                url = f"{self.base_url}/rest/v1/{table}"
                
                # Ø¥Ø¹Ø¯Ø§Ø¯ headers Ù„Ù„upsert
                upsert_headers = self.headers.copy()
                upsert_headers['Prefer'] = 'resolution=merge-duplicates'
                
                response = requests.post(url, headers=upsert_headers, json=batch)
                
                if response.status_code in [200, 201]:
                    success_count += len(batch)
                    logger.info(f"âœ… {label} - Ù†Ø¬Ø­Øª Ø§Ù„Ø¯ÙØ¹Ø© {batch_num}: {len(batch)} Ø³Ø¬Ù„")
                else:
                    failed_count += len(batch)
                    failed_records.extend(batch)
                    logger.error(f"âŒ {label} - ÙØ´Ù„Øª Ø§Ù„Ø¯ÙØ¹Ø© {batch_num}: {response.status_code}")
                    logger.error(f"ØªÙØ§ØµÙŠÙ„ Ø§Ù„Ø®Ø·Ø£: {response.text}")
                    
                    # Ù…Ø­Ø§ÙˆÙ„Ø© Ø¥Ø±Ø³Ø§Ù„ Ø§Ù„Ø³Ø¬Ù„Ø§Øª ÙˆØ§Ø­Ø¯Ø§Ù‹ ØªÙ„Ùˆ Ø§Ù„Ø¢Ø®Ø± ÙÙŠ Ø­Ø§Ù„Ø© ÙØ´Ù„ Ø§Ù„Ø¯ÙØ¹Ø©
                    self._retry_individual_records(table, batch, label)
                    
            except Exception as e:
                failed_count += len(batch)
                failed_records.extend(batch)
                logger.error(f"âŒ {label} - Ø§Ø³ØªØ«Ù†Ø§Ø¡ ÙÙŠ Ø§Ù„Ø¯ÙØ¹Ø© {batch_num}: {str(e)}")
            
            # ØªÙˆÙ‚Ù Ù‚ØµÙŠØ± Ø¨ÙŠÙ† Ø§Ù„Ø¯ÙØ¹Ø§Øª Ù„ØªØ¬Ù†Ø¨ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø®Ø§Ø¯Ù…
            time.sleep(0.5)
        
        # Ø­ÙØ¸ Ø§Ù„Ø³Ø¬Ù„Ø§Øª Ø§Ù„ÙØ§Ø´Ù„Ø© Ù„Ù„Ù…Ø±Ø§Ø¬Ø¹Ø©
        if failed_records:
            self._save_failed_records(table, failed_records, label)
        
        logger.info(f"ğŸ“Š {label} - Ø§Ù„Ù†ØªÙŠØ¬Ø© Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠØ©: Ù†Ø§Ø¬Ø­Ø© {success_count}, ÙØ§Ø´Ù„Ø© {failed_count}")
        return {"success": success_count, "failed": failed_count}
    
    def _retry_individual_records(self, table: str, batch: List[Dict], label: str):
        """Ø¥Ø¹Ø§Ø¯Ø© Ù…Ø­Ø§ÙˆÙ„Ø© Ø¥Ø±Ø³Ø§Ù„ Ø§Ù„Ø³Ø¬Ù„Ø§Øª ÙˆØ§Ø­Ø¯Ø§Ù‹ ØªÙ„Ùˆ Ø§Ù„Ø¢Ø®Ø±"""
        logger.info(f"ğŸ”„ {label} - Ù…Ø­Ø§ÙˆÙ„Ø© Ø¥Ø±Ø³Ø§Ù„ Ø§Ù„Ø³Ø¬Ù„Ø§Øª Ù…Ù†ÙØ±Ø¯Ø©...")
        
        url = f"{self.base_url}/rest/v1/{table}"
        headers = self.headers.copy()
        headers['Prefer'] = 'resolution=merge-duplicates'
        
        for record in batch:
            try:
                response = requests.post(url, headers=headers, json=[record])
                if response.status_code in [200, 201]:
                    logger.debug(f"âœ… {label} - Ù†Ø¬Ø­ Ø§Ù„Ø³Ø¬Ù„ {record.get('id', 'ØºÙŠØ± Ù…Ø­Ø¯Ø¯')}")
                else:
                    logger.warning(f"âš ï¸ {label} - ÙØ´Ù„ Ø§Ù„Ø³Ø¬Ù„ {record.get('id', 'ØºÙŠØ± Ù…Ø­Ø¯Ø¯')}: {response.text}")
            except Exception as e:
                logger.warning(f"âš ï¸ {label} - Ø§Ø³ØªØ«Ù†Ø§Ø¡ ÙÙŠ Ø§Ù„Ø³Ø¬Ù„ {record.get('id', 'ØºÙŠØ± Ù…Ø­Ø¯Ø¯')}: {str(e)}")
    
    def _save_failed_records(self, table: str, failed_records: List[Dict], label: str):
        """Ø­ÙØ¸ Ø§Ù„Ø³Ø¬Ù„Ø§Øª Ø§Ù„ÙØ§Ø´Ù„Ø© ÙÙŠ Ù…Ù„Ù Ù„Ù„Ù…Ø±Ø§Ø¬Ø¹Ø©"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"failed_{table}_{timestamp}.json"
        
        try:
            import json
            with open(filename, 'w', encoding='utf-8') as f:
                json.dump(failed_records, f, ensure_ascii=False, indent=2)
            logger.info(f"ğŸ’¾ {label} - ØªÙ… Ø­ÙØ¸ {len(failed_records)} Ø³Ø¬Ù„ ÙØ§Ø´Ù„ ÙÙŠ {filename}")
        except Exception as e:
            logger.error(f"âŒ ÙØ´Ù„ ÙÙŠ Ø­ÙØ¸ Ø§Ù„Ø³Ø¬Ù„Ø§Øª Ø§Ù„ÙØ§Ø´Ù„Ø©: {str(e)}")

def fetch_with_retry(url: str, headers: Dict[str, str], params: Optional[Dict] = None, retries: int = 3, delay: int = 2) -> Optional[Dict]:
    """Ø¬Ù„Ø¨ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ø¹ Ø¥Ø¹Ø§Ø¯Ø© Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø© ÙÙŠ Ø­Ø§Ù„Ø© Ø§Ù„ÙØ´Ù„"""
    for attempt in range(retries):
        try:
            response = requests.get(url, headers=headers, params=params, timeout=30)
            if response.status_code == 200:
                return response.json()
            else:
                logger.warning(f"âš ï¸ Ù…Ø­Ø§ÙˆÙ„Ø© {attempt+1} ÙØ´Ù„Øª: {response.status_code} - {response.text}")
        except requests.exceptions.Timeout:
            logger.warning(f"âš ï¸ Ù…Ø­Ø§ÙˆÙ„Ø© {attempt+1} Ø§Ù†ØªÙ‡Øª Ø§Ù„Ù…Ù‡Ù„Ø© Ø§Ù„Ø²Ù…Ù†ÙŠØ©")
        except Exception as e:
            logger.warning(f"âš ï¸ Ù…Ø­Ø§ÙˆÙ„Ø© {attempt+1} ÙØ´Ù„Øª: {str(e)}")
        
        if attempt < retries - 1:  # Ù„Ø§ Ù†ØªÙˆÙ‚Ù ÙÙŠ Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø© Ø§Ù„Ø£Ø®ÙŠØ±Ø©
            time.sleep(delay * (attempt + 1))  # Ø²ÙŠØ§Ø¯Ø© ÙˆÙ‚Øª Ø§Ù„ØªÙˆÙ‚Ù Ù…Ø¹ ÙƒÙ„ Ù…Ø­Ø§ÙˆÙ„Ø©
    
    return None

def fetch_invoice_details(inv_id: str) -> Optional[Dict]:
    """Ø¬Ù„Ø¨ ØªÙØ§ØµÙŠÙ„ Ø§Ù„ÙØ§ØªÙˆØ±Ø© Ù…Ø¹ Ø§Ù„Ø¨Ù†ÙˆØ¯"""
    url = f"{BASE_URL}/v2/api/entity/invoice/{inv_id}?include=invoice_item"
    return fetch_with_retry(url, HEADERS_DAFTRA)

def fetch_all():
    """Ø§Ù„Ø¯Ø§Ù„Ø© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ© Ù„Ø¬Ù„Ø¨ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ÙˆØ­ÙØ¸Ù‡Ø§ ÙÙŠ Supabase"""
    logger.info("ğŸš€ Ø¨Ø¯Ø¡ Ø¹Ù…Ù„ÙŠØ© Ø¬Ù„Ø¨ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ù† Ø¯ÙØªØ±Ø©...")
    
    # Ø¥Ù†Ø´Ø§Ø¡ Ø¹Ù…ÙŠÙ„ Supabase Ù…Ø­Ø³Ù†
    supabase_client = SupabaseClient(SUPABASE_URL, HEADERS_SUPABASE)
    
    # Ø¥Ù†Ø´Ø§Ø¡ Ù…Ø¯Ù‚Ù‚ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
    validator = DataValidator()
    
    all_invoices = []
    all_items = []
    processing_stats = {
        "total_invoices_processed": 0,
        "total_items_processed": 0,
        "validation_errors": 0,
        "api_errors": 0
    }
    
    for branch in BRANCH_IDS:
        logger.info(f"ğŸ¢ Ø¨Ø¯Ø¡ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ÙØ±Ø¹ {branch}")
        page = 1
        branch_invoices = 0
        branch_items = 0
        
        while True:
            url = f"{BASE_URL}/v2/api/entity/invoice/list/1"
            params = {
                "filter[branch_id]": branch,
                "page": page,
                "limit": PAGE_LIMIT
            }
            
            logger.info(f"ğŸ“„ Ø¬Ù„Ø¨ Ø§Ù„ØµÙØ­Ø© {page} Ù„Ù„ÙØ±Ø¹ {branch}...")
            data = fetch_with_retry(url, HEADERS_DAFTRA, params=params)
            
            if data is None:
                logger.error(f"âŒ ÙØ´Ù„ ÙÙŠ Ø¬Ù„Ø¨ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù„Ù„ÙØ±Ø¹ {branch} Ø§Ù„ØµÙØ­Ø© {page}")
                processing_stats["api_errors"] += 1
                break
            
            items = data.get("data") or []
            if not isinstance(items, list):
                items = [items]
            
            # ØªØµÙÙŠØ© Ø§Ù„ÙÙˆØ§ØªÙŠØ± Ø­Ø³Ø¨ Ø§Ù„Ù†ÙˆØ¹ Ø§Ù„Ù…Ø·Ù„ÙˆØ¨
            valid_items = [inv for inv in items if int(inv.get("type", -1)) == EXPECTED_TYPE]
            logger.info(f"ğŸ“‹ ÙØ±Ø¹ {branch} - ØµÙØ­Ø© {page}: {len(valid_items)} ÙØ§ØªÙˆØ±Ø© ØµØ§Ù„Ø­Ø© Ù…Ù† Ø£ØµÙ„ {len(items)}")
            
            if not valid_items:
                logger.info(f"âœ… Ø§Ù†ØªÙ‡Ø§Ø¡ ÙÙˆØ§ØªÙŠØ± Ø§Ù„ÙØ±Ø¹ {branch} ÙÙŠ Ø§Ù„ØµÙØ­Ø© {page}")
                break
            
            # Ù…Ø¹Ø§Ù„Ø¬Ø© ÙƒÙ„ ÙØ§ØªÙˆØ±Ø©
            for inv in valid_items:
                try:
                    # Ø¬Ù„Ø¨ ØªÙØ§ØµÙŠÙ„ Ø§Ù„ÙØ§ØªÙˆØ±Ø©
                    invoice_data = fetch_invoice_details(inv["id"])
                    if not invoice_data:
                        logger.error(f"âŒ ÙØ´Ù„ ÙÙŠ Ø¬Ù„Ø¨ ØªÙØ§ØµÙŠÙ„ Ø§Ù„ÙØ§ØªÙˆØ±Ø© {inv['id']}")
                        processing_stats["api_errors"] += 1
                        continue
                    
                    # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ÙˆØ¬ÙˆØ¯ Ø§Ù„Ø¨Ù†ÙˆØ¯
                    invoice_items = invoice_data.get("invoice_item")
                    if not isinstance(invoice_items, list):
                        logger.warning(f"âš ï¸ Ø§Ù„ÙØ§ØªÙˆØ±Ø© {inv['id']} Ù„Ø§ ØªØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ø¨Ù†ÙˆØ¯ ØµØ§Ù„Ø­Ø©")
                        invoice_items = []
                    
                    logger.info(f"ğŸ“‘ Ø§Ù„ÙØ§ØªÙˆØ±Ø© {inv['id']}: {len(invoice_items)} Ø¨Ù†Ø¯")
                    
                    # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ØµØ­Ø© Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ÙØ§ØªÙˆØ±Ø©
                    try:
                        validated_invoice = validator.validate_invoice(invoice_data)
                        all_invoices.append(validated_invoice)
                        branch_invoices += 1
                        processing_stats["total_invoices_processed"] += 1
                    except ValueError as e:
                        logger.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„ÙØ§ØªÙˆØ±Ø© {inv['id']}: {str(e)}")
                        processing_stats["validation_errors"] += 1
                        continue
                    
                    # Ù…Ø¹Ø§Ù„Ø¬Ø© Ø¨Ù†ÙˆØ¯ Ø§Ù„ÙØ§ØªÙˆØ±Ø©
                    client_name = invoice_data.get("client_business_name", "")
                    for item in invoice_items:
                        try:
                            validated_item = validator.validate_invoice_item(
                                item, 
                                invoice_data["id"], 
                                client_name
                            )
                            all_items.append(validated_item)
                            branch_items += 1
                            processing_stats["total_items_processed"] += 1
                        except ValueError as e:
                            logger.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ø¨Ù†Ø¯ {item.get('id', 'ØºÙŠØ± Ù…Ø­Ø¯Ø¯')}: {str(e)}")
                            processing_stats["validation_errors"] += 1
                            continue
                
                except Exception as e:
                    logger.error(f"âŒ Ø®Ø·Ø£ Ø¹Ø§Ù… ÙÙŠ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ÙØ§ØªÙˆØ±Ø© {inv['id']}: {str(e)}")
                    processing_stats["api_errors"] += 1
                    continue
            
            # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù†ØªÙ‡Ø§Ø¡ Ø§Ù„ØµÙØ­Ø§Øª
            if len(items) < PAGE_LIMIT:
                logger.info(f"âœ… Ø§Ù†ØªÙ‡Ø§Ø¡ ÙÙˆØ§ØªÙŠØ± Ø§Ù„ÙØ±Ø¹ {branch} - Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„ØµÙØ­Ø§Øª: {page}")
                break
            
            page += 1
            time.sleep(1)  # ØªÙˆÙ‚Ù Ù‚ØµÙŠØ± Ø¨ÙŠÙ† Ø§Ù„ØµÙØ­Ø§Øª
        
        logger.info(f"ğŸ“Š Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„ÙØ±Ø¹ {branch}: {branch_invoices} ÙØ§ØªÙˆØ±Ø©ØŒ {branch_items} Ø¨Ù†Ø¯")
    
    # Ø·Ø¨Ø§Ø¹Ø© Ø§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠØ©
    logger.info("ğŸ“Š Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠØ©:")
    logger.info(f"   - Ø§Ù„ÙÙˆØ§ØªÙŠØ± Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©: {processing_stats['total_invoices_processed']}")
    logger.info(f"   - Ø§Ù„Ø¨Ù†ÙˆØ¯ Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©: {processing_stats['total_items_processed']}")
    logger.info(f"   - Ø£Ø®Ø·Ø§Ø¡ Ø§Ù„ØªØ­Ù‚Ù‚: {processing_stats['validation_errors']}")
    logger.info(f"   - Ø£Ø®Ø·Ø§Ø¡ API: {processing_stats['api_errors']}")
    
    # Ø­ÙØ¸ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ÙÙŠ Supabase
    results = {}
    
    if all_invoices:
        logger.info(f"ğŸ”„ Ø¨Ø¯Ø¡ Ø±ÙØ¹ {len(all_invoices)} ÙØ§ØªÙˆØ±Ø© Ø¥Ù„Ù‰ Supabase...")
        results["invoices"] = supabase_client.upsert_data("invoices", all_invoices, "Ø§Ù„ÙÙˆØ§ØªÙŠØ±")
    else:
        logger.warning("âš ï¸ Ù„Ø§ ØªÙˆØ¬Ø¯ ÙÙˆØ§ØªÙŠØ± Ù„Ù„Ø±ÙØ¹")
        results["invoices"] = {"success": 0, "failed": 0}
    
    if all_items:
        logger.info(f"ğŸ”„ Ø¨Ø¯Ø¡ Ø±ÙØ¹ {len(all_items)} Ø¨Ù†Ø¯ Ø¥Ù„Ù‰ Supabase...")
        results["items"] = supabase_client.upsert_data("invoice_items", all_items, "Ø¨Ù†ÙˆØ¯ Ø§Ù„ÙÙˆØ§ØªÙŠØ±")
    else:
        logger.warning("âš ï¸ Ù„Ø§ ØªÙˆØ¬Ø¯ Ø¨Ù†ÙˆØ¯ Ù„Ù„Ø±ÙØ¹")
        results["items"] = {"success": 0, "failed": 0}
    
    # ØªÙ‚Ø±ÙŠØ± Ù†Ù‡Ø§Ø¦ÙŠ
    logger.info("ğŸ‰ Ø§Ù†ØªÙ‡Ø§Ø¡ Ø§Ù„Ø¹Ù…Ù„ÙŠØ© - Ø§Ù„ØªÙ‚Ø±ÙŠØ± Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ:")
    logger.info(f"   ğŸ“‹ Ø§Ù„ÙÙˆØ§ØªÙŠØ±: {results['invoices']['success']} Ù†Ø¬Ø­ØªØŒ {results['invoices']['failed']} ÙØ´Ù„Øª")
    logger.info(f"   ğŸ“ Ø§Ù„Ø¨Ù†ÙˆØ¯: {results['items']['success']} Ù†Ø¬Ø­ØŒ {results['items']['failed']} ÙØ´Ù„")
    
    return {
        "processing_stats": processing_stats,
        "upload_results": results,
        "summary": {
            "total_invoices": len(all_invoices),
            "total_items": len(all_items),
            "successful_invoices": results["invoices"]["success"],
            "successful_items": results["items"]["success"]
        }
    }

if __name__ == "__main__":
    try:
        result = fetch_all()
        print("âœ… Ø§Ù„Ø¹Ù…Ù„ÙŠØ© Ø§ÙƒØªÙ…Ù„Øª Ø¨Ù†Ø¬Ø§Ø­")
        print(f"Ø§Ù„Ù†ØªØ§Ø¦Ø¬: {result['summary']}")
    except Exception as e:
        logger.error(f"âŒ Ø®Ø·Ø£ Ø¹Ø§Ù… ÙÙŠ ØªØ´ØºÙŠÙ„ Ø§Ù„Ø¨Ø±Ù†Ø§Ù…Ø¬: {str(e)}")
        raise

