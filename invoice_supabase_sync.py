import time
import requests
import logging
import json
from datetime import datetime
from typing import List, Dict, Any, Optional
import os

# Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ù…ØªØºÙŠØ±Ø§Øª Ù…Ø¨Ø§Ø´Ø±Ø©
BASE_URL = os.getenv("DAFTRA_URL", "https://shadowpeace.daftra.com/v2/api")
DAFTRA_API_KEY = os.getenv("DAFTRA_APIKEY")
SUPABASE_URL = os.getenv("SUPABASE_URL", "").rstrip("/") + "/rest/v1"
SUPABASE_KEY = os.getenv("SUPABASE_KEY")

HEADERS_DAFTRA = {
    "apikey": DAFTRA_API_KEY,
    "Content-Type": "application/json"
}

HEADERS_SUPABASE = {
    "apikey": SUPABASE_KEY,
    "Authorization": f"Bearer {SUPABASE_KEY}",
    "Content-Type": "application/json",
    "Prefer": "return=minimal"
}

EXPECTED_TYPE = 0  # Ù„Ù„Ù…Ø¨ÙŠØ¹Ø§Øª
PAGE_LIMIT = 50
BRANCH_IDS = [2, 3]
BATCH_SIZE = 100
MAX_RETRIES = 3
RETRY_DELAY = 2

# Ø¥Ø¹Ø¯Ø§Ø¯ Ù†Ø¸Ø§Ù… Ø§Ù„ØªØ³Ø¬ÙŠÙ„ Ø§Ù„Ù…ÙØµÙ„
logging.basicConfig(
    level=logging.DEBUG, 
    format="%(asctime)s - %(levelname)s - %(message)s",
    handlers=[
        logging.FileHandler('daftra_sync.log', encoding='utf-8'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

class DataValidator:
    """ÙØ¦Ø© Ù„Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ØµØ­Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù‚Ø¨Ù„ Ø§Ù„Ø¥Ø±Ø³Ø§Ù„"""
    
    @staticmethod
    def validate_invoice(invoice: Dict[str, Any]) -> bool:
        """Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ØµØ­Ø© Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ÙØ§ØªÙˆØ±Ø©"""
        required_fields = ['id']
        return all(field in invoice and invoice[field] is not None for field in required_fields)
    
    @staticmethod
    def validate_item(item: Dict[str, Any]) -> bool:
        """Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ØµØ­Ø© Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø¨Ù†Ø¯"""
        required_fields = ['id']
        return all(field in item and item[field] is not None for field in required_fields)
    
    @staticmethod
    def clean_invoice_data(invoice: Dict[str, Any]) -> Dict[str, Any]:
        """ØªÙ†Ø¸ÙŠÙ ÙˆØªØ­ÙˆÙŠÙ„ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ÙØ§ØªÙˆØ±Ø©"""
        cleaned = {
            'id': str(invoice.get('id', '')),
            'invoice_no': str(invoice.get('no', '')),
            'invoice_date': DataValidator.format_date(invoice.get('date')),
            'customer_id': str(invoice.get('customer_id', '')),
            'total': float(invoice.get('total', 0)),
            'branch': int(invoice.get('store_id', 0)),
            'client_business_name': str(invoice.get('client_business_name', ''))[:255],
            'client_city': str(invoice.get('client_city', ''))[:100],
            'summary_paid': float(invoice.get('summary_paid', 0)),
            'summary_unpaid': float(invoice.get('summary_unpaid', 0)),
            'created_at': datetime.now().isoformat(),
            'updated_at': datetime.now().isoformat()
        }
        return cleaned
    
    @staticmethod
    def clean_item_data(item: Dict[str, Any], invoice_id: str, client_name: str) -> Dict[str, Any]:
        """ØªÙ†Ø¸ÙŠÙ ÙˆØªØ­ÙˆÙŠÙ„ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø¨Ù†Ø¯"""
        cleaned = {
            'id': str(item.get('id', '')),
            'invoice_id': str(invoice_id),
            'quantity': float(item.get('quantity', 0)),
            'unit_price': float(item.get('unit_price', 0)),
            'total_price': float(item.get('total_price', 0)),
            'product_id': str(item.get('product_id', '')),
            'product_code': str(item.get('product_code', ''))[:50],
            'client_business_name': str(client_name)[:255],
            'created_at': datetime.now().isoformat(),
            'updated_at': datetime.now().isoformat()
        }
        return cleaned
    
    @staticmethod
    def format_date(date_str: Any) -> Optional[str]:
        """ØªØ­ÙˆÙŠÙ„ Ø§Ù„ØªØ§Ø±ÙŠØ® Ø¥Ù„Ù‰ ØµÙŠØºØ© ISO"""
        if not date_str:
            return None
        
        try:
            if isinstance(date_str, str):
                # Ù…Ø­Ø§ÙˆÙ„Ø© ØªØ­ÙˆÙŠÙ„ Ø§Ù„ØªØ§Ø±ÙŠØ® Ù…Ù† ØµÙŠØº Ù…Ø®ØªÙ„ÙØ©
                for fmt in ['%Y-%m-%d', '%Y-%m-%d %H:%M:%S', '%d/%m/%Y']:
                    try:
                        dt = datetime.strptime(date_str, fmt)
                        return dt.isoformat()
                    except ValueError:
                        continue
            return str(date_str)
        except Exception:
            return None

class SupabaseClient:
    """Ø¹Ù…ÙŠÙ„ Ù…Ø­Ø³Ù† Ù„Ù„ØªØ¹Ø§Ù…Ù„ Ù…Ø¹ Supabase"""
    
    def __init__(self):
        self.base_url = SUPABASE_URL
        self.headers = HEADERS_SUPABASE
        self.session = requests.Session()
        self.session.headers.update(self.headers)
        logger.info(f"ğŸ”— Supabase URL: {self.base_url}")
        logger.info(f"ğŸ”‘ Supabase Key: {SUPABASE_KEY[:20]}...")
    
    def upsert_batch(self, table: str, data: List[Dict[str, Any]]) -> tuple[int, int]:
        """Ø¥Ø¯Ø±Ø§Ø¬ Ø£Ùˆ ØªØ­Ø¯ÙŠØ« Ø¯ÙØ¹Ø© Ù…Ù† Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª"""
        if not data:
            return 0, 0
        
        url = f"{self.base_url}/{table}"
        logger.info(f"ğŸ“¤ Ù…Ø­Ø§ÙˆÙ„Ø© Ø­ÙØ¸ {len(data)} Ø³Ø¬Ù„ ÙÙŠ Ø¬Ø¯ÙˆÙ„ {table}")
        logger.debug(f"ğŸ”— URL: {url}")
        logger.debug(f"ğŸ“‹ Ø¹ÙŠÙ†Ø© Ù…Ù† Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª: {json.dumps(data[0], indent=2, ensure_ascii=False)}")
        
        for attempt in range(MAX_RETRIES):
            try:
                response = self.session.post(url, json=data, timeout=30)
                
                logger.info(f"ğŸ“Š Ø§Ø³ØªØ¬Ø§Ø¨Ø© Supabase: {response.status_code}")
                logger.debug(f"ğŸ“„ Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ø§Ø³ØªØ¬Ø§Ø¨Ø©: {response.text}")
                
                if response.status_code in [200, 201]:
                    logger.info(f"âœ… ØªÙ… Ø­ÙØ¸ {len(data)} Ø³Ø¬Ù„ ÙÙŠ Ø¬Ø¯ÙˆÙ„ {table}")
                    return len(data), 0
                else:
                    logger.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø­ÙØ¸ {table}: {response.status_code}")
                    logger.error(f"ğŸ“„ ØªÙØ§ØµÙŠÙ„ Ø§Ù„Ø®Ø·Ø£: {response.text}")
                    
            except requests.exceptions.RequestException as e:
                logger.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ø§ØªØµØ§Ù„ Ù…Ø¹ Supabase (Ù…Ø­Ø§ÙˆÙ„Ø© {attempt + 1}): {e}")
                if attempt < MAX_RETRIES - 1:
                    time.sleep(RETRY_DELAY)
                    
        return 0, len(data)

class DaftraClient:
    """Ø¹Ù…ÙŠÙ„ Ù…Ø­Ø³Ù† Ù„Ù„ØªØ¹Ø§Ù…Ù„ Ù…Ø¹ API Ø¯ÙØªØ±Ø©"""
    
    def __init__(self):
        self.base_url = BASE_URL
        self.headers = HEADERS_DAFTRA
        self.session = requests.Session()
        self.session.headers.update(self.headers)
        logger.info(f"ğŸ”— Daftra URL: {self.base_url}")
        logger.info(f"ğŸ”‘ Daftra API Key: {DAFTRA_API_KEY[:20]}...")
    
    def fetch_invoices(self, branch_id: int, page: int = 1) -> Dict[str, Any]:
        """Ø¬Ù„Ø¨ Ø§Ù„ÙÙˆØ§ØªÙŠØ± Ù…Ù† ÙØ±Ø¹ Ù…Ø¹ÙŠÙ†"""
        url = f"{self.base_url}/entity/invoice/list/1"
        params = {
            'filter[type]': EXPECTED_TYPE,
            'filter[branch_id]': branch_id,
            'page': page,
            'limit': PAGE_LIMIT
        }
        
        logger.info(f"ğŸ“¡ Ø·Ù„Ø¨ API: {url}")
        logger.info(f"ğŸ“‹ Ø§Ù„Ù…Ø¹Ø§Ù…Ù„Ø§Øª: {params}")
        logger.debug(f"ğŸ”‘ Headers: {self.headers}")
        
        for attempt in range(MAX_RETRIES):
            try:
                response = self.session.get(url, params=params, timeout=30)
                
                logger.info(f"ğŸ“Š Ø§Ø³ØªØ¬Ø§Ø¨Ø© Ø¯ÙØªØ±Ø©: {response.status_code}")
                logger.debug(f"ğŸ“„ Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ø§Ø³ØªØ¬Ø§Ø¨Ø©: {response.text[:500]}...")
                
                if response.status_code == 200:
                    data = response.json()
                    logger.info(f"ğŸ“‹ Ø¹Ø¯Ø¯ Ø§Ù„ÙÙˆØ§ØªÙŠØ± Ø§Ù„Ù…Ø³ØªÙ„Ù…Ø©: {len(data.get('data', []))}")
                    return data
                else:
                    logger.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø¬Ù„Ø¨ Ø§Ù„ÙÙˆØ§ØªÙŠØ±: {response.status_code}")
                    logger.error(f"ğŸ“„ ØªÙØ§ØµÙŠÙ„ Ø§Ù„Ø®Ø·Ø£: {response.text}")
                    
            except requests.exceptions.RequestException as e:
                logger.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ø§ØªØµØ§Ù„ Ù…Ø¹ Ø¯ÙØªØ±Ø© (Ù…Ø­Ø§ÙˆÙ„Ø© {attempt + 1}): {e}")
                if attempt < MAX_RETRIES - 1:
                    time.sleep(RETRY_DELAY)
            except json.JSONDecodeError as e:
                logger.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ ØªØ­Ù„ÙŠÙ„ JSON: {e}")
                logger.error(f"ğŸ“„ Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ø§Ø³ØªØ¬Ø§Ø¨Ø©: {response.text}")
                    
        return {}

def process_branch_invoices(daftra_client: DaftraClient, supabase_client: SupabaseClient, branch_id: int) -> Dict[str, int]:
    """Ù…Ø¹Ø§Ù„Ø¬Ø© ÙÙˆØ§ØªÙŠØ± ÙØ±Ø¹ ÙˆØ§Ø­Ø¯"""
    logger.info(f"ğŸ¢ Ø¨Ø¯Ø¡ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ÙØ±Ø¹ {branch_id}")
    
    stats = {
        'invoices_processed': 0,
        'items_processed': 0,
        'invoices_saved': 0,
        'items_saved': 0,
        'invoices_failed': 0,
        'items_failed': 0
    }
    
    page = 1
    invoices_batch = []
    items_batch = []
    
    while True:
        logger.info(f"ğŸ“„ Ø¬Ù„Ø¨ Ø§Ù„ØµÙØ­Ø© {page} Ù„Ù„ÙØ±Ø¹ {branch_id}...")
        
        response_data = daftra_client.fetch_invoices(branch_id, page)
        
        if not response_data:
            logger.warning(f"âš ï¸ Ù„Ø§ ØªÙˆØ¬Ø¯ Ø§Ø³ØªØ¬Ø§Ø¨Ø© Ù…Ù† API Ù„Ù„ØµÙØ­Ø© {page} Ù„Ù„ÙØ±Ø¹ {branch_id}")
            break
            
        if 'data' not in response_data:
            logger.warning(f"âš ï¸ Ù„Ø§ ÙŠÙˆØ¬Ø¯ Ù…ÙØªØ§Ø­ 'data' ÙÙŠ Ø§Ù„Ø§Ø³ØªØ¬Ø§Ø¨Ø© Ù„Ù„ØµÙØ­Ø© {page} Ù„Ù„ÙØ±Ø¹ {branch_id}")
            logger.debug(f"ğŸ“„ Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ø§Ø³ØªØ¬Ø§Ø¨Ø©: {json.dumps(response_data, indent=2, ensure_ascii=False)}")
            break
            
        invoices = response_data['data']
        
        if not invoices:
            logger.info(f"âœ… Ø§Ù†ØªÙ‡Ø§Ø¡ ÙÙˆØ§ØªÙŠØ± Ø§Ù„ÙØ±Ø¹ {branch_id} ÙÙŠ Ø§Ù„ØµÙØ­Ø© {page}")
            break
        
        valid_invoices = 0
        
        for invoice in invoices:
            logger.debug(f"ğŸ“‹ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ÙØ§ØªÙˆØ±Ø©: {json.dumps(invoice, indent=2, ensure_ascii=False)}")
            
            if not DataValidator.validate_invoice(invoice):
                logger.warning(f"âš ï¸ ÙØ§ØªÙˆØ±Ø© ØºÙŠØ± ØµØ§Ù„Ø­Ø©: {invoice}")
                continue
                
            # ØªÙ†Ø¸ÙŠÙ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ÙØ§ØªÙˆØ±Ø©
            try:
                cleaned_invoice = DataValidator.clean_invoice_data(invoice)
                invoices_batch.append(cleaned_invoice)
                valid_invoices += 1
                logger.debug(f"âœ… ØªÙ… ØªÙ†Ø¸ÙŠÙ Ø§Ù„ÙØ§ØªÙˆØ±Ø©: {cleaned_invoice}")
                
                # Ù…Ø¹Ø§Ù„Ø¬Ø© Ø¨Ù†ÙˆØ¯ Ø§Ù„ÙØ§ØªÙˆØ±Ø©
                items = invoice.get('items', [])
                client_name = invoice.get('client_business_name', '')
                
                for item in items:
                    if DataValidator.validate_item(item):
                        cleaned_item = DataValidator.clean_item_data(item, invoice['id'], client_name)
                        items_batch.append(cleaned_item)
                        logger.debug(f"âœ… ØªÙ… ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ø¨Ù†Ø¯: {cleaned_item}")
                        
            except Exception as e:
                logger.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ÙØ§ØªÙˆØ±Ø© {invoice.get('id', 'ØºÙŠØ± Ù…Ø¹Ø±ÙˆÙ')}: {e}")
                continue
        
        logger.info(f"ğŸ“‹ ÙØ±Ø¹ {branch_id} - ØµÙØ­Ø© {page}: {valid_invoices} ÙØ§ØªÙˆØ±Ø© ØµØ§Ù„Ø­Ø© Ù…Ù† Ø£ØµÙ„ {len(invoices)}")
        stats['invoices_processed'] += valid_invoices
        stats['items_processed'] += len(items_batch)
        
        # Ø­ÙØ¸ Ø§Ù„Ø¯ÙØ¹Ø§Øª Ø¹Ù†Ø¯ Ø§Ù„ÙˆØµÙˆÙ„ Ù„Ù„Ø­Ø¯ Ø§Ù„Ø£Ù‚ØµÙ‰
        if len(invoices_batch) >= BATCH_SIZE:
            saved, failed = supabase_client.upsert_batch('invoices', invoices_batch)
            stats['invoices_saved'] += saved
            stats['invoices_failed'] += failed
            invoices_batch = []
            
        if len(items_batch) >= BATCH_SIZE:
            saved, failed = supabase_client.upsert_batch('invoice_items', items_batch)
            stats['items_saved'] += saved
            stats['items_failed'] += failed
            items_batch = []
        
        page += 1
        
        # Ø­Ù…Ø§ÙŠØ© Ù…Ù† Ø§Ù„Ø­Ù„Ù‚Ø§Øª Ø§Ù„Ù„Ø§Ù†Ù‡Ø§Ø¦ÙŠØ©
        if page > 100:
            logger.warning(f"âš ï¸ ØªÙ… Ø§Ù„ÙˆØµÙˆÙ„ Ù„Ù„Ø­Ø¯ Ø§Ù„Ø£Ù‚ØµÙ‰ Ù…Ù† Ø§Ù„ØµÙØ­Ø§Øª Ù„Ù„ÙØ±Ø¹ {branch_id}")
            break
    
    # Ø­ÙØ¸ Ø§Ù„Ø¯ÙØ¹Ø§Øª Ø§Ù„Ù…ØªØ¨Ù‚ÙŠØ©
    if invoices_batch:
        saved, failed = supabase_client.upsert_batch('invoices', invoices_batch)
        stats['invoices_saved'] += saved
        stats['invoices_failed'] += failed
        
    if items_batch:
        saved, failed = supabase_client.upsert_batch('invoice_items', items_batch)
        stats['items_saved'] += saved
        stats['items_failed'] += failed
    
    logger.info(f"ğŸ“Š Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„ÙØ±Ø¹ {branch_id}: {stats['invoices_processed']} ÙØ§ØªÙˆØ±Ø©ØŒ {stats['items_processed']} Ø¨Ù†Ø¯")
    return stats

def main():
    """Ø§Ù„Ø¯Ø§Ù„Ø© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©"""
    logger.info("ğŸš€ Ø¨Ø¯Ø¡ Ø¹Ù…Ù„ÙŠØ© Ø¬Ù„Ø¨ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ù† Ø¯ÙØªØ±Ø©...")
    
    # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ù…ØªØºÙŠØ±Ø§Øª Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø©
    logger.info(f"ğŸ” Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ù…ØªØºÙŠØ±Ø§Øª Ø§Ù„Ø¨ÙŠØ¦Ø©...")
    logger.info(f"   - DAFTRA_API_KEY: {'âœ… Ù…ÙˆØ¬ÙˆØ¯' if DAFTRA_API_KEY else 'âŒ Ù…ÙÙ‚ÙˆØ¯'}")
    logger.info(f"   - SUPABASE_URL: {'âœ… Ù…ÙˆØ¬ÙˆØ¯' if SUPABASE_URL else 'âŒ Ù…ÙÙ‚ÙˆØ¯'}")
    logger.info(f"   - SUPABASE_KEY: {'âœ… Ù…ÙˆØ¬ÙˆØ¯' if SUPABASE_KEY else 'âŒ Ù…ÙÙ‚ÙˆØ¯'}")
    
    if not all([DAFTRA_API_KEY, SUPABASE_URL, SUPABASE_KEY]):
        logger.error("âŒ Ù…ØªØºÙŠØ±Ø§Øª Ø§Ù„Ø¨ÙŠØ¦Ø© Ù…ÙÙ‚ÙˆØ¯Ø©!")
        return
    
    # Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ø¹Ù…Ù„Ø§Ø¡
    try:
        daftra_client = DaftraClient()
        supabase_client = SupabaseClient()
    except Exception as e:
        logger.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ø¹Ù…Ù„Ø§Ø¡: {e}")
        return
    
    # Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø¥Ø¬Ù…Ø§Ù„ÙŠØ©
    total_stats = {
        'invoices_processed': 0,
        'items_processed': 0,
        'invoices_saved': 0,
        'items_saved': 0,
        'invoices_failed': 0,
        'items_failed': 0
    }
    
    # Ù…Ø¹Ø§Ù„Ø¬Ø© ÙƒÙ„ ÙØ±Ø¹
    for branch_id in BRANCH_IDS:
        try:
            branch_stats = process_branch_invoices(daftra_client, supabase_client, branch_id)
            
            # ØªØ¬Ù…ÙŠØ¹ Ø§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª
            for key in total_stats:
                total_stats[key] += branch_stats[key]
                
        except Exception as e:
            logger.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ÙØ±Ø¹ {branch_id}: {e}")
            import traceback
            logger.error(f"ğŸ“„ ØªÙØ§ØµÙŠÙ„ Ø§Ù„Ø®Ø·Ø£: {traceback.format_exc()}")
    
    # Ø§Ù„ØªÙ‚Ø±ÙŠØ± Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ
    logger.info("ğŸ“Š Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠØ©:")
    logger.info(f"   - Ø§Ù„ÙÙˆØ§ØªÙŠØ± Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©: {total_stats['invoices_processed']}")
    logger.info(f"   - Ø§Ù„Ø¨Ù†ÙˆØ¯ Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©: {total_stats['items_processed']}")
    logger.info(f"   - Ø§Ù„ÙÙˆØ§ØªÙŠØ± Ø§Ù„Ù…Ø­ÙÙˆØ¸Ø©: {total_stats['invoices_saved']}")
    logger.info(f"   - Ø§Ù„Ø¨Ù†ÙˆØ¯ Ø§Ù„Ù…Ø­ÙÙˆØ¸Ø©: {total_stats['items_saved']}")
    logger.info(f"   - Ø£Ø®Ø·Ø§Ø¡ Ø§Ù„ÙÙˆØ§ØªÙŠØ±: {total_stats['invoices_failed']}")
    logger.info(f"   - Ø£Ø®Ø·Ø§Ø¡ Ø§Ù„Ø¨Ù†ÙˆØ¯: {total_stats['items_failed']}")
    
    if total_stats['invoices_processed'] == 0:
        logger.warning("âš ï¸ Ù„Ø§ ØªÙˆØ¬Ø¯ ÙÙˆØ§ØªÙŠØ± Ù„Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©")
    
    logger.info("ğŸ‰ Ø§Ù†ØªÙ‡Ø§Ø¡ Ø§Ù„Ø¹Ù…Ù„ÙŠØ© - Ø§Ù„ØªÙ‚Ø±ÙŠØ± Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ:")
    logger.info(f"   ğŸ“‹ Ø§Ù„ÙÙˆØ§ØªÙŠØ±: {total_stats['invoices_saved']} Ù†Ø¬Ø­ØªØŒ {total_stats['invoices_failed']} ÙØ´Ù„Øª")
    logger.info(f"   ğŸ“ Ø§Ù„Ø¨Ù†ÙˆØ¯: {total_stats['items_saved']} Ù†Ø¬Ø­ØŒ {total_stats['items_failed']} ÙØ´Ù„")

# Ø¥Ø¶Ø§ÙØ© alias Ù„Ù„ØªÙˆØ§ÙÙ‚ Ù…Ø¹ main.py
fetch_all = main

if __name__ == "__main__":
    main()

