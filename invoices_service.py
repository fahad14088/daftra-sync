import os
import requests
import time
import logging
import hashlib

# â€”â€”â€”â€”â€”â€”â€”â€” Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ù„ÙˆØ¬ â€”â€”â€”â€”â€”â€”â€”â€”
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# â€”â€”â€”â€”â€”â€”â€”â€” Ù…ØªØºÙŠØ±Ø§Øª Ø§Ù„Ø¨ÙŠØ¦Ø© â€”â€”â€”â€”â€”â€”â€”â€”
BASE_URL       = os.getenv("BASE_URL", "").rstrip('/')            # Ù…Ø«Ø§Ù„: "https://shadowpeace.daftra.com"
DAFTRA_APIKEY  = os.getenv("DAFTRA_APIKEY", "")
DAFTRA_HEADERS = {"apikey": DAFTRA_APIKEY}
SUPABASE_URL   = os.getenv("SUPABASE_URL", "").rstrip('/')
SUPABASE_KEY   = os.getenv("SUPABASE_KEY", "")

# â€”â€”â€”â€”â€”â€”â€”â€” Ø¯ÙˆØ§Ù„ Ù…Ø³Ø§Ø¹Ø¯Ø© â€”â€”â€”â€”â€”â€”â€”â€”

def generate_uuid(s: str) -> str:
    """ØªÙˆÙ„ÙŠØ¯ UUID Ø«Ø§Ø¨Øª Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ù†Øµ."""
    h = hashlib.md5(s.encode()).hexdigest()
    return f"{h[:8]}-{h[8:12]}-{h[12:16]}-{h[16:20]}-{h[20:32]}"

def safe_float(v, default=0.0):
    """ØªØ­ÙˆÙŠÙ„ Ø¢Ù…Ù† Ø¥Ù„Ù‰ float."""
    try:
        if v is None or v == "":
            return default
        return float(str(v).replace(",", ""))
    except:
        return default

def fetch_with_retry(url, headers, params=None, retries=3, timeout=30):
    """GET Ù…Ø¹ Ø¥Ø­Ø§Ø·Ø© Ø¥Ø¹Ø§Ø¯Ø© Ù…Ø­Ø§ÙˆÙ„Ø© ØªÙ„Ù‚Ø§Ø¦ÙŠØ© ÙÙŠ Ø­Ø§Ù„ Ø§Ù„Ø®Ø·Ø£."""
    for i in range(retries):
        try:
            r = requests.get(url, headers=headers, params=params, timeout=timeout)
            if r.status_code == 200:
                return r.json()
            logger.warning(f"âš ï¸ GET {r.url} â†’ {r.status_code}")
        except Exception as e:
            logger.warning(f"âš ï¸ Exception on GET {url}: {e}")
        time.sleep((i + 1) * 2)
    return None

def upsert(table: str, payload: dict) -> bool:
    """INSERT Ø£Ùˆ UPDATE ÙÙŠ Supabase REST Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… on_conflict=id."""
    url = f"{SUPABASE_URL}/rest/v1/{table}?on_conflict=id"
    headers = {
        "apikey":        SUPABASE_KEY,
        "Authorization": f"Bearer {SUPABASE_KEY}",
        "Content-Type":  "application/json",
        "Prefer":        "resolution=merge-duplicates"
    }
    r = requests.post(url, headers=headers, json=payload, timeout=30)
    if r.status_code in (200, 201, 409):
        return True
    logger.error(f"âŒ upsert {table} failed [{r.status_code}]: {r.text}")
    return False

def get_all_branches():
    """Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„ÙØ±ÙˆØ¹ Ø§Ù„Ø«Ø§Ø¨ØªØ© Ù„Ø¯ÙŠÙƒ."""
    branches = [{"id": 1}, {"id": 2}]
    ids = [b["id"] for b in branches]
    logger.info(f"âœ… Ø§Ù„ÙØ±ÙˆØ¹: {ids}")
    return ids

# â€”â€”â€”â€”â€”â€”â€”â€” Ø¯Ø§Ù„Ø© Ø§Ù„Ù…Ø²Ø§Ù…Ù†Ø© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ© â€”â€”â€”â€”â€”â€”â€”â€”

def sync_invoices():
    limit = 100      # Ø±ÙØ¹ Ø§Ù„Ø­Ø¯ Ù„ØªÙ‚Ù„ÙŠÙ„ Ø¹Ø¯Ø¯ Ø§Ù„ØµÙØ­Ø§Øª
    total_inv = 0
    total_items = 0

    for branch_id in get_all_branches():
        page = 1
        while True:
            # 1) Ø¬Ù„Ø¨ Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„ÙÙˆØ§ØªÙŠØ± Ù…Ø¹ Ø§Ù„Ø¨Ù†ÙˆØ¯ ÙÙŠ Ù†ÙØ³ Ø§Ù„Ø·Ù„Ø¨
            url_list = f"{BASE_URL}/v2/api/entity/invoice/list/1"
            params = {
                "filter[branch_id]": branch_id,
                "page": page,
                "limit": limit,
                "with[]": "InvoiceItem"
            }
            data = fetch_with_retry(url_list, DAFTRA_HEADERS, params=params)
            if not data:
                break

            inv_list = data.get("data", [])
            logger.info(f"ğŸ“„ ÙØ±Ø¹ {branch_id} ØµÙØ­Ø© {page}: {len(inv_list)} ÙØ§ØªÙˆØ±Ø§Øª")
            if not inv_list:
                break

            # 2) Ø­ÙØ¸ ÙƒÙ„ ÙØ§ØªÙˆØ±Ø© ÙˆØ¨Ù†ÙˆØ¯Ù‡Ø§
            for inv in inv_list:
                inv_id = str(inv.get("id"))
                items = inv.get("InvoiceItem") or []
                if not isinstance(items, list):
                    items = [items]

                if not items:
                    logger.error(f"âŒ ÙØ§ØªÙˆØ±Ø© {inv_id} Ø¨Ø¯ÙˆÙ† Ø¨Ù†ÙˆØ¯ â†’ ØªØ®Ø·Ù‘ÙŠ")
                    continue

                logger.info(f"âœ… ÙØ§ØªÙˆØ±Ø© {inv_id} ØªØ­ØªÙˆÙŠ {len(items)} Ø¨Ù†ÙˆØ¯")

                # Ø­ÙØ¸ Ø§Ù„ÙØ§ØªÙˆØ±Ø©
                inv_uuid = generate_uuid(inv_id)
                payload_inv = {
                    "id":            inv_uuid,
                    "invoice_no":    inv.get("no", ""),
                    "total":         safe_float(inv.get("summary_total") or inv.get("total")),
                    "invoice_date":  inv.get("date", ""),
                    "branch":        branch_id,
                }
                if upsert("invoices", payload_inv):
                    total_inv += 1

                    # Ø­ÙØ¸ Ø§Ù„Ø¨Ù†ÙˆØ¯
                    for it in items:
                        item_uuid = generate_uuid(f"{it.get('id')}-{inv_id}")
                        payload_it = {
                            "id":          item_uuid,
                            "invoice_id":  inv_uuid,
                            "product_id":  it.get("product_id", ""),
                            "quantity":    safe_float(it.get("quantity")),
                            "unit_price":  safe_float(it.get("unit_price") or it.get("price")),
                            "total_price": safe_float(it.get("quantity")) *
                                           safe_float(it.get("unit_price") or it.get("price"))
                        }
                        if upsert("invoice_items", payload_it):
                            total_items += 1

            # Ø¥Ø°Ø§ Ø§Ù„ØµÙØ­Ø© ÙƒØ§Ù†Øª ÙƒØ§Ù…Ù„Ø© Ù†ÙƒÙ…Ù„ØŒ ÙˆØ¥Ù„Ø§ Ù†Ù†Ù‡ÙŠ
            if len(inv_list) < limit:
                break
            page += 1
            time.sleep(0.1)

    logger.info(f"ğŸ‰ Ø§Ù†ØªÙ‡Ù‰ Ø§Ù„ØªØ²Ø§Ù…Ù†: ÙÙˆØ§ØªÙŠØ± Ù…Ø­ÙÙˆØ¸Ø©={total_inv}, Ø¨Ù†ÙˆØ¯ Ù…Ø­ÙÙˆØ¸Ø©={total_items}")

if __name__ == "__main__":
    sync_invoices()
