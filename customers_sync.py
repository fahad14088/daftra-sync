import time
import requests
import logging
import json
import os
from datetime import datetime
from typing import Dict, List, Any, Optional

# Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„ØªØ³Ø¬ÙŠÙ„
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler(),
        logging.FileHandler('customers_sync.log')
    ]
)
logger = logging.getLogger(__name__)

# Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ù…ØªØºÙŠØ±Ø§Øª
BASE_URL = os.getenv("DAFTRA_URL", "https://shadowpeace.daftra.com") + "/v2/api"
DAFTRA_API_KEY = os.getenv("DAFTRA_APIKEY")
SUPABASE_URL = os.getenv("SUPABASE_URL", "").rstrip("/") + "/rest/v1"
SUPABASE_KEY = os.getenv("SUPABASE_KEY")

HEADERS_DAFTRA = {
    "apikey": DAFTRA_API_KEY,
    "Content-Type": "application/json"
}

HEADERS_SUPABASE = {
    "apikey": SUPABASE_KEY,
    "Authorization": f"Bearer {SUPABASE_KEY}",
    "Content-Type": "application/json",
    "Prefer": "resolution=merge-duplicates"
}

BATCH_SIZE = 50
PAGE_LIMIT = 20

class SupabaseClient:
    def __init__(self, base_url: str, headers: Dict[str, str]):
        self.base_url = base_url
        self.headers = headers
        self.session = requests.Session()
        self.session.headers.update(headers)

    def upsert_batch(self, table: str, data: List[Dict[str, Any]]) -> tuple[int, int]:
        """Ø­ÙØ¸ Ø¯ÙØ¹Ø© Ù…Ù† Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ø¹ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ØªÙƒØ±Ø§Ø±"""
        if not data:
            return 0, 0

        url = f"{self.base_url}/{table}?on_conflict=id"
        
        try:
            # Ù…Ø­Ø§ÙˆÙ„Ø© Ø£ÙˆÙ„Ù‰: merge-duplicates
            headers_with_upsert = {**self.headers, "Prefer": "resolution=merge-duplicates"}
            response = self.session.post(url, json=data, headers=headers_with_upsert, timeout=30)
            
            if response.status_code in [200, 201]:
                logger.info(f"âœ… ØªÙ… Ø­ÙØ¸/ØªØ­Ø¯ÙŠØ« {len(data)} Ø³Ø¬Ù„ ÙÙŠ Ø¬Ø¯ÙˆÙ„ {table}")
                return len(data), 0
            elif response.status_code == 409:
                # Ù…Ø­Ø§ÙˆÙ„Ø© Ø«Ø§Ù†ÙŠØ©: ignore-duplicates
                headers_with_ignore = {**self.headers, "Prefer": "resolution=ignore-duplicates"}
                response = self.session.post(url, json=data, headers=headers_with_ignore, timeout=30)
                
                if response.status_code in [200, 201]:
                    logger.info(f"âœ… ØªÙ… ØªØ¬Ø§Ù‡Ù„ Ø§Ù„ØªÙƒØ±Ø§Ø± ÙˆØ­ÙØ¸ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø¬Ø¯ÙŠØ¯Ø© ÙÙŠ Ø¬Ø¯ÙˆÙ„ {table}")
                    return len(data), 0
                else:
                    logger.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø­ÙØ¸ {table}: {response.status_code} - {response.text}")
                    return 0, len(data)
            else:
                logger.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø­ÙØ¸ {table}: {response.status_code} - {response.text}")
                return 0, len(data)
                
        except Exception as e:
            logger.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ø§ØªØµØ§Ù„ Ø¨Ù€ Supabase: {str(e)}")
            return 0, len(data)

class DaftraCustomersSync:
    def __init__(self):
        self.base_url = BASE_URL
        self.headers = HEADERS_DAFTRA
        self.supabase_client = SupabaseClient(SUPABASE_URL, HEADERS_SUPABASE)
        self.session = requests.Session()
        self.session.headers.update(self.headers)

    def fetch_customers_page(self, page: int = 1) -> Optional[Dict[str, Any]]:
        """Ø¬Ù„Ø¨ ØµÙØ­Ø© Ù…Ù† Ø§Ù„Ø¹Ù…Ù„Ø§Ø¡ Ù…Ù† Ø¯ÙØªØ±Ø©"""
        url = f"{self.base_url}/entity/client/list/1"
        params = {
            'page': page,
            'limit': PAGE_LIMIT
        }
        
        logger.info(f"ğŸ“„ Ø¬Ù„Ø¨ Ø§Ù„ØµÙØ­Ø© {page} Ù…Ù† Ø§Ù„Ø¹Ù…Ù„Ø§Ø¡...")
        
        for attempt in range(3):
            try:
                response = self.session.get(url, params=params, timeout=30)
                
                if response.status_code == 200:
                    data = response.json()
                    if data and 'data' in data:
                        customers = data['data']
                        logger.info(f"ğŸ“‹ ØµÙØ­Ø© {page}: {len(customers)} Ø¹Ù…ÙŠÙ„")
                        return data
                    else:
                        logger.warning(f"âš ï¸ Ù„Ø§ ØªÙˆØ¬Ø¯ Ø¨ÙŠØ§Ù†Ø§Øª ÙÙŠ Ø§Ù„ØµÙØ­Ø© {page}")
                        return None
                else:
                    logger.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø¬Ù„Ø¨ Ø§Ù„Ø¹Ù…Ù„Ø§Ø¡: {response.status_code}")
                    
            except Exception as e:
                logger.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ø§ØªØµØ§Ù„ (Ù…Ø­Ø§ÙˆÙ„Ø© {attempt + 1}): {str(e)}")
                if attempt < 2:
                    time.sleep(2)
                    
        return None

    @staticmethod
    def clean_customer_data(customer: Dict[str, Any]) -> Dict[str, Any]:
        """ØªÙ†Ø¸ÙŠÙ ÙˆØªØ­ÙˆÙŠÙ„ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø¹Ù…ÙŠÙ„ Ù„Ù„ØµÙŠØºØ© Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø©"""
        cleaned = {
            'id': str(customer.get('id', '')),
            'customer_code': str(customer.get('code', '')),
            'name': str(customer.get('name', ''))[:255],
            'phone': str(customer.get('phone', ''))[:50],
            'email': str(customer.get('email', ''))[:255],
            'gender': str(customer.get('gender', ''))[:10],
            'birth_date': customer.get('birth_date'),
            'city': str(customer.get('city', ''))[:100],
            'region': str(customer.get('region', ''))[:100],
            'address': str(customer.get('address', ''))[:500],
            'total_spent': float(customer.get('total_spent', 0)),
            'total_invoices': int(customer.get('total_invoices', 0)),
            'max_order_value': float(customer.get('max_order_value', 0)),
            'average_order_value': float(customer.get('average_order_value', 0)),
            'payment_total': float(customer.get('payment_total', 0)),
            'last_order_date': customer.get('last_order_date'),
            'order_frequency_days': int(customer.get('order_frequency_days', 0)),
            'is_active': bool(customer.get('is_active', True)),
            'created_at': datetime.now().isoformat(),
            'updated_at': datetime.now().isoformat()
        }
        
        # ØªÙ†Ø¸ÙŠÙ Ø§Ù„ØªÙˆØ§Ø±ÙŠØ®
        if cleaned['birth_date'] and cleaned['birth_date'] != '0000-00-00':
            try:
                # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ØµØ­Ø© Ø§Ù„ØªØ§Ø±ÙŠØ®
                datetime.strptime(cleaned['birth_date'], '%Y-%m-%d')
            except:
                cleaned['birth_date'] = None
        else:
            cleaned['birth_date'] = None
            
        if cleaned['last_order_date'] and cleaned['last_order_date'] != '0000-00-00':
            try:
                # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ØµØ­Ø© Ø§Ù„ØªØ§Ø±ÙŠØ®
                datetime.strptime(cleaned['last_order_date'], '%Y-%m-%d')
            except:
                cleaned['last_order_date'] = None
        else:
            cleaned['last_order_date'] = None
        
        return cleaned

    def sync_customers(self):
        """Ù…Ø²Ø§Ù…Ù†Ø© Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø¹Ù…Ù„Ø§Ø¡ Ù…Ù† Ø¯ÙØªØ±Ø© Ø¥Ù„Ù‰ Supabase"""
        logger.info("ğŸš€ Ø¨Ø¯Ø¡ Ø¹Ù…Ù„ÙŠØ© Ù…Ø²Ø§Ù…Ù†Ø© Ø§Ù„Ø¹Ù…Ù„Ø§Ø¡...")
        
        page = 1
        customers_batch = []
        total_stats = {
            'customers_processed': 0,
            'customers_saved': 0,
            'customers_failed': 0
        }
        
        while True:
            # Ø¬Ù„Ø¨ ØµÙØ­Ø© Ù…Ù† Ø§Ù„Ø¹Ù…Ù„Ø§Ø¡
            response_data = self.fetch_customers_page(page)
            
            if not response_data or 'data' not in response_data:
                logger.info(f"âœ… Ø§Ù†ØªÙ‡Ø§Ø¡ Ø§Ù„Ø¹Ù…Ù„Ø§Ø¡ ÙÙŠ Ø§Ù„ØµÙØ­Ø© {page}")
                break
                
            customers = response_data['data']
            
            if not customers:
                logger.info(f"âœ… Ù„Ø§ ØªÙˆØ¬Ø¯ Ø¹Ù…Ù„Ø§Ø¡ ÙÙŠ Ø§Ù„ØµÙØ­Ø© {page}")
                break
            
            # Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø¹Ù…Ù„Ø§Ø¡
            for customer in customers:
                try:
                    cleaned_customer = self.clean_customer_data(customer)
                    customers_batch.append(cleaned_customer)
                    total_stats['customers_processed'] += 1
                    
                except Exception as e:
                    logger.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø¹Ù…ÙŠÙ„ {customer.get('id', 'unknown')}: {str(e)}")
                    total_stats['customers_failed'] += 1
            
            # Ø­ÙØ¸ Ø§Ù„Ø¯ÙØ¹Ø© Ø¹Ù†Ø¯ Ø§Ù„ÙˆØµÙˆÙ„ Ù„Ù„Ø­Ø¯ Ø§Ù„Ø£Ù‚ØµÙ‰
            if len(customers_batch) >= BATCH_SIZE:
                saved, failed = self.supabase_client.upsert_batch('customers', customers_batch)
                total_stats['customers_saved'] += saved
                total_stats['customers_failed'] += failed
                customers_batch = []
                
                # Ø§Ù†ØªØ¸Ø§Ø± Ù‚ØµÙŠØ± Ù„ØªØ¬Ù†Ø¨ Ø§Ù„Ø¶ØºØ· Ø¹Ù„Ù‰ Ø§Ù„Ø®Ø§Ø¯Ù…
                time.sleep(1)
            
            page += 1
            
            # Ø­Ø¯ Ø£Ù‚ØµÙ‰ Ù„Ù„ØµÙØ­Ø§Øª (Ø­Ù…Ø§ÙŠØ©)
            if page > 1000:
                logger.warning(f"âš ï¸ ØªÙ… Ø§Ù„ÙˆØµÙˆÙ„ Ù„Ù„Ø­Ø¯ Ø§Ù„Ø£Ù‚ØµÙ‰ Ù…Ù† Ø§Ù„ØµÙØ­Ø§Øª")
                break
        
        # Ø­ÙØ¸ Ø§Ù„Ø¹Ù…Ù„Ø§Ø¡ Ø§Ù„Ù…ØªØ¨Ù‚ÙŠÙ†
        if customers_batch:
            saved, failed = self.supabase_client.upsert_batch('customers', customers_batch)
            total_stats['customers_saved'] += saved
            total_stats['customers_failed'] += failed
        
        # Ø·Ø¨Ø§Ø¹Ø© Ø§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠØ©
        logger.info("ğŸ“Š Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠØ©:")
        logger.info(f"   - Ø§Ù„Ø¹Ù…Ù„Ø§Ø¡ Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬ÙŠÙ†: {total_stats['customers_processed']}")
        logger.info(f"   - Ø§Ù„Ø¹Ù…Ù„Ø§Ø¡ Ø§Ù„Ù…Ø­ÙÙˆØ¸ÙŠÙ†: {total_stats['customers_saved']}")
        logger.info(f"   - Ø£Ø®Ø·Ø§Ø¡ Ø§Ù„Ø¹Ù…Ù„Ø§Ø¡: {total_stats['customers_failed']}")
        
        if total_stats['customers_processed'] == 0:
            logger.warning("âš ï¸ Ù„Ø§ ØªÙˆØ¬Ø¯ Ø¹Ù…Ù„Ø§Ø¡ Ù„Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©")
        
        logger.info("ğŸ‰ Ø§Ù†ØªÙ‡Ø§Ø¡ Ø¹Ù…Ù„ÙŠØ© Ù…Ø²Ø§Ù…Ù†Ø© Ø§Ù„Ø¹Ù…Ù„Ø§Ø¡ - Ø§Ù„ØªÙ‚Ø±ÙŠØ± Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ:")
        logger.info(f"   ğŸ‘¥ Ø§Ù„Ø¹Ù…Ù„Ø§Ø¡: {total_stats['customers_saved']} Ù†Ø¬Ø­ØŒ {total_stats['customers_failed']} ÙØ´Ù„")
        
        return total_stats

def main():
    """Ø§Ù„Ø¯Ø§Ù„Ø© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©"""
    try:
        print("ğŸ”„ Ù…Ø²Ø§Ù…Ù†Ø© Ø§Ù„Ø¹Ù…Ù„Ø§Ø¡...")
        print(f"SUPABASE={SUPABASE_URL}")
        
        # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ù…ØªØºÙŠØ±Ø§Øª Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø©
        if not all([DAFTRA_API_KEY, SUPABASE_URL, SUPABASE_KEY]):
            logger.error("âŒ Ù…ØªØºÙŠØ±Ø§Øª Ø§Ù„Ø¨ÙŠØ¦Ø© Ù…ÙÙ‚ÙˆØ¯Ø©!")
            return
        
        # Ø¥Ù†Ø´Ø§Ø¡ Ù…Ø«ÙŠÙ„ Ø§Ù„Ù…Ø²Ø§Ù…Ù†Ø© ÙˆØªØ´ØºÙŠÙ„Ù‡Ø§
        sync = DaftraCustomersSync()
        stats = sync.sync_customers()
        
        print(f"âœ… ØªÙ… Ø§Ù„Ø§Ù†ØªÙ‡Ø§Ø¡! Ø§Ù„Ø¹Ù…Ù„Ø§Ø¡ Ø§Ù„Ù…Ø­ÙÙˆØ¸ÙŠÙ†: {stats['customers_saved']}")
        
    except Exception as e:
        logger.error(f"âŒ Ø®Ø·Ø£ Ø¹Ø§Ù…: {str(e)}")
        print(f"âŒ Ø®Ø·Ø£ Ø¹Ø§Ù…: {str(e)}")

if __name__ == "__main__":
    main()

# Ø¥Ø¶Ø§ÙØ© alias Ù„Ù„ØªÙˆØ§ÙÙ‚ Ù…Ø¹ main.py
fetch_all = main

